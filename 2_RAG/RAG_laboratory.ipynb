{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "## 课程基本信息"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1",
   "metadata": {},
   "source": [
    "- **课程名称**：大数据与商务智能 - 检索增强生成（RAG）系统实践\n",
    "- **授课对象**：中山大学工商管理非全专硕MBA学生\n",
    "- **课时**：3学时（上机课）\n",
    "- **前置知识**：基础Python编程能力，LLM基础应用能力"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2",
   "metadata": {},
   "source": [
    "完成本课程后，您将能够：\n",
    "1. 独立搭建基于Milvus和LlamaIndex的RAG系统，实现企业知识库检索\n",
    "2. 掌握向量数据库的索引优化和性能调优方法，提升检索效率30%以上\n",
    "3. 设计并实现混合检索（密集+稀疏向量）解决方案，提高查询准确率\n",
    "4. 运用Cherry Studio可视化工具构建完整的企业知识库应用\n",
    "5. 具备RAG系统部署和维护的基本能力，识别并解决常见问题"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3",
   "metadata": {},
   "source": [
    "## 2.1 RAG环境配置（以windows为例）"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4",
   "metadata": {},
   "source": [
    "### 2.1.1 创建虚拟环境"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5",
   "metadata": {},
   "source": [
    "### 2.1.2 下载安装Milvus向量数据库\n",
    "Windows: https://github.com/milvus-io/milvus/releases/download/v2.4.0/milvus-standalone-windows-amd64.zip\n",
    "\n",
    "macOS: https://github.com/milvus-io/milvus/releases/download/v2.4.0/milvus-standalone-darwin-amd64.zip\n",
    "\n",
    "Linux: https://github.com/milvus-io/milvus/releases/download/v2.4.0/milvus-standalone-linux-amd64.tar.gz"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6",
   "metadata": {},
   "source": [
    "### 2.1.3 解压并启动Milvus"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7",
   "metadata": {},
   "source": [
    "### 2.1.4 验证Milvus是否启动成功"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8",
   "metadata": {},
   "source": [
    "### 2.1.5 安装Ollama与模型（如未安装）\n",
    "下载地址：https://ollama.com/download\n",
    "\n",
    "安装完成后下载模型\n",
    "ollama pull llama3:8b"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9",
   "metadata": {},
   "source": [
    "## 2.2 基础RAG系统构建与高级优化"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10",
   "metadata": {},
   "source": [
    "### 2.2.1 文档加载与预处理"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11",
   "metadata": {},
   "source": [
    "创建`1_basic_rag/document_loader.py`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import SimpleDirectoryReader, Document\n",
    "from llama_index.core.node_parser import SentenceSplitter\n",
    "from typing import List\n",
    "from datetime import datetime\n",
    "\n",
    "def load_and_process_documents(\n",
    "    data_dir: str = \"../data\",\n",
    "    chunk_size: int = 512,\n",
    "    chunk_overlap: int = 20\n",
    ") -> List[Document]:\n",
    "    \"\"\"\n",
    "    加载文档并进行分块处理（继承LLM课程的文档处理技术）\n",
    "    \"\"\"\n",
    "    # 1. 加载文档\n",
    "    print(f\"从 {data_dir} 加载文档...\")\n",
    "    reader = SimpleDirectoryReader(\n",
    "        input_dir=data_dir,\n",
    "        recursive=True,\n",
    "        required_exts=[\".pdf\", \".docx\", \".txt\"],\n",
    "    )\n",
    "    \n",
    "    documents = reader.load_data()\n",
    "    print(f\"成功加载 {len(documents)} 个文档\")\n",
    "    \n",
    "    # 2. 添加元数据（扩展LLM课程的元数据管理）\n",
    "    for doc in documents:\n",
    "        file_name = doc.metadata.get(\"file_name\", \"unknown_source\")\n",
    "        doc.metadata[\"source\"] = file_name\n",
    "        doc.metadata[\"processed_date\"] = str(datetime.now().date())\n",
    "        doc.metadata[\"course\"] = \"RAG\"  # 新增课程标识\n",
    "        \n",
    "    # 3. 文档分块（优化LLM课程的分块策略）\n",
    "    print(f\"对文档进行分块处理 (chunk_size={chunk_size}, chunk_overlap={chunk_overlap})\")\n",
    "    parser = SentenceSplitter(\n",
    "        chunk_size=chunk_size,\n",
    "        chunk_overlap=chunk_overlap,\n",
    "        separator=\"\\n\\n\"  # 优先按段落分割\n",
    "    )\n",
    "    \n",
    "    nodes = parser.get_nodes_from_documents(documents)\n",
    "    \n",
    "    print(f\"文档分块完成，共生成 {len(nodes)} 个文档块\")\n",
    "    print(f\"示例块内容: {nodes[0].text[:100]}...\")\n",
    "    \n",
    "    return nodes\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    nodes = load_and_process_documents()\n",
    "    \n",
    "    # 保存处理结果\n",
    "    import pickle\n",
    "    with open(\"processed_nodes.pkl\", \"wb\") as f:\n",
    "        pickle.dump(nodes, f)\n",
    "    print(\"文档处理结果已保存至 processed_nodes.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13",
   "metadata": {},
   "source": [
    "### 2.2.2 向量数据库集成"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14",
   "metadata": {},
   "source": [
    "创建`1_basic_rag/vector_db_setup.py`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import VectorStoreIndex, StorageContext\n",
    "from llama_index.vector_stores.milvus import MilvusVectorStore\n",
    "from llama_index.embeddings.huggingface import HuggingFaceEmbedding\n",
    "import pickle\n",
    "from datetime import datetime\n",
    "\n",
    "def build_rag_index(\n",
    "    nodes_path: str = \"processed_nodes.pkl\",\n",
    "    collection_name: str = \"basic_rag_collection\",\n",
    "    overwrite: bool = True\n",
    "):\n",
    "    \"\"\"\n",
    "    构建RAG系统索引（LLM课程向量应用的进阶实现）\n",
    "    \"\"\"\n",
    "    # 1. 加载预处理文档\n",
    "    print(f\"从 {nodes_path} 加载文档块...\")\n",
    "    with open(nodes_path, \"rb\") as f:\n",
    "        nodes = pickle.load(f)\n",
    "    print(f\"加载完成，共 {len(nodes)} 个文档块\")\n",
    "    \n",
    "    # 2. 初始化嵌入模型（扩展LLM课程的模型应用）\n",
    "    print(\"初始化嵌入模型...\")\n",
    "    embed_model = HuggingFaceEmbedding(\n",
    "        model_name=\"BAAI/bge-base-en-v1.5\",\n",
    "        embed_batch_size=16\n",
    "    )\n",
    "    \n",
    "    # 3. 配置Milvus向量存储（RAG特有技术点）\n",
    "    print(f\"连接Milvus向量数据库，集合名称: {collection_name}\")\n",
    "    vector_store = MilvusVectorStore(\n",
    "        uri=\"./milvus_rag.db\",  # 本地文件存储\n",
    "        collection_name=collection_name,\n",
    "        dim=768,  # BGE模型输出维度\n",
    "        overwrite=overwrite,\n",
    "        similarity_metric=\"COSINE\",\n",
    "        index_config={\n",
    "            \"index_type\": \"HNSW\",  # 高效近似最近邻索引\n",
    "            \"params\": {\"M\": 16, \"efConstruction\": 256}\n",
    "        }\n",
    "    )\n",
    "    \n",
    "    # 4. 创建索引\n",
    "    storage_context = StorageContext.from_defaults(vector_store=vector_store)\n",
    "    index = VectorStoreIndex.from_documents(\n",
    "        nodes,\n",
    "        storage_context=storage_context,\n",
    "        embed_model=embed_model\n",
    "    )\n",
    "    \n",
    "    print(\"RAG索引构建完成\")\n",
    "    return index\n",
    "\n",
    "def create_query_engine(index):\n",
    "    \"\"\"创建查询引擎（继承LLM课程的查询设计）\"\"\"\n",
    "    query_engine = index.as_query_engine(\n",
    "        similarity_top_k=5,  # 返回前5个相关文档\n",
    "        streaming=False\n",
    "    )\n",
    "    return query_engine\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    index = build_rag_index()\n",
    "    \n",
    "    # 创建查询引擎\n",
    "    query_engine = create_query_engine(index)\n",
    "    \n",
    "    # 测试查询（使用LLM课程相同的测试案例，便于对比）\n",
    "    test_queries = [\n",
    "        \"企业去年的营收是多少？\",\n",
    "        \"产品的核心功能有哪些？\",\n",
    "        \"营销策略包含哪些渠道？\"\n",
    "    ]\n",
    "    \n",
    "    print(\"\\n===== 测试RAG系统 =====对比LLM直出结果====\")\n",
    "    for query in test_queries:\n",
    "        print(f\"查询: {query}\")\n",
    "        response = query_engine.query(query)\n",
    "        print(f\"RAG增强回答: {str(response)[:200]}...\\n\")\n",
    "    \n",
    "    # 保存索引配置\n",
    "    index.storage_context.persist(persist_dir=\"rag_index_storage\")\n",
    "    print(\"索引配置已保存至 rag_index_storage 目录\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16",
   "metadata": {},
   "source": [
    "### 2.2.3 高级RAG技术应用"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17",
   "metadata": {},
   "source": [
    "#### 2.2.3.1 混合检索系统实现"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import VectorStoreIndex, StorageContext\n",
    "from llama_index.vector_stores.milvus import MilvusVectorStore\n",
    "from llama_index.embeddings.huggingface import HuggingFaceEmbedding\n",
    "from llama_index.core.embeddings import SparseEmbedding\n",
    "from typing import List, Dict, Any\n",
    "import os\n",
    "import pickle\n",
    "from rank_bm25 import BM25Okapi\n",
    "\n",
    "# 自定义BM25稀疏嵌入函数（RAG高级技术）\n",
    "class BM25SparseEmbeddingFunction:\n",
    "    def __init__(self):\n",
    "        self.bm25 = None\n",
    "        self.tokenizer = lambda x: x.split()\n",
    "        self.corpus = []\n",
    "        self.vocab = set()\n",
    "\n",
    "    def fit(self, texts: List[str]):\n",
    "        \"\"\"训练BM25模型\"\"\"\n",
    "        self.corpus = [self.tokenizer(text) for text in texts]\n",
    "        self.bm25 = BM25Okapi(self.corpus)\n",
    "        # 收集词汇表\n",
    "        for doc in self.corpus:\n",
    "            self.vocab.update(doc)\n",
    "        return self\n",
    "\n",
    "    def __call__(self, text: str) -> SparseEmbedding:\n",
    "        \"\"\"生成稀疏嵌入\"\"\"\n",
    "        tokens = self.tokenizer(text)\n",
    "        doc_scores = self.bm25.get_scores(tokens)\n",
    "        \n",
    "        # 创建稀疏向量（仅保留非零分数）\n",
    "        indices = [i for i, score in enumerate(doc_scores) if score > 0]\n",
    "        values = [float(score) for score in doc_scores if score > 0]\n",
    "        \n",
    "        return SparseEmbedding(indices=indices, values=values)\n",
    "\n",
    "def build_hybrid_rag_system():\n",
    "    \"\"\"构建混合检索RAG系统（RAG进阶内容）\"\"\"\n",
    "    # 1. 加载预处理文档\n",
    "    with open(\"processed_nodes.pkl\", \"rb\") as f:\n",
    "        nodes = pickle.load(f)\n",
    "    texts = [node.text for node in nodes]\n",
    "    \n",
    "    # 2. 初始化嵌入模型（融合LLM与检索技术）\n",
    "    dense_embed_model = HuggingFaceEmbedding(model_name=\"BAAI/bge-base-en-v1.5\")\n",
    "    sparse_embed_model = BM25SparseEmbeddingFunction().fit(texts)\n",
    "    \n",
    "    # 3. 配置Milvus混合检索\n",
    "    vector_store = MilvusVectorStore(\n",
    "        uri=\"./milvus_hybrid.db\",\n",
    "        collection_name=\"hybrid_rag_collection\",\n",
    "        dim=768,\n",
    "        overwrite=True,\n",
    "        enable_sparse=True,\n",
    "        sparse_embedding_function=sparse_embed_model,\n",
    "        hybrid_ranker=\"WeightedRanker\",\n",
    "        hybrid_ranker_params={\"weights\": [0.7, 0.3]}  # 密集:稀疏 = 7:3\n",
    "    )\n",
    "    \n",
    "    # 4. 创建索引\n",
    "    storage_context = StorageContext.from_defaults(vector_store=vector_store)\n",
    "    index = VectorStoreIndex.from_documents(\n",
    "        nodes,\n",
    "        storage_context=storage_context,\n",
    "        embed_model=dense_embed_model\n",
    "    )\n",
    "    \n",
    "    print(\"混合检索RAG系统构建完成\")\n",
    "    return index"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19",
   "metadata": {},
   "source": [
    "#### 2.2.3.2 性能优化策略"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20",
   "metadata": {},
   "source": [
    "1. **异步查询实现**：\n",
    "```python\n",
    "async def batch_query(self, queries: list) -> list:\n",
    "    \"\"\"批量执行异步查询（RAG性能优化技术）\"\"\"\n",
    "    tasks = [self.async_query(q) for q in queries]\n",
    "    results = await asyncio.gather(*tasks)\n",
    "    return results\n",
    "```\n",
    "\n",
    "2. **索引优化对比**：\n",
    "```python\n",
    "index_params_list = [\n",
    "    {\"index_type\": \"IVF_FLAT\", \"params\": {\"nlist\": 128}},  # 基础索引\n",
    "    {\"index_type\": \"HNSW\", \"params\": {\"M\": 16, \"efConstruction\": 256}}  # 优化索引\n",
    "]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21",
   "metadata": {},
   "source": [
    "## 2.3 使用Cherry Studio构建知识库"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22",
   "metadata": {},
   "source": [
    "### 2.3.1 Cherry Studio知识库功能概述"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23",
   "metadata": {},
   "source": [
    "Cherry Studio提供了完整的知识库管理功能，支持从文档导入、向量化处理到检索优化的全流程可视化操作。根据[官方文档](https://docs.cherry-ai.com/knowledge-base/knowledge-base)，其核心功能包括：\n",
    "\n",
    "- **多源文档导入**：支持PDF、Word、TXT等多种格式\n",
    "- **智能分块处理**：自动优化文档分块策略\n",
    "- **向量存储管理**：支持Milvus/FAISS等多种向量数据库\n",
    "- **检索策略配置**：灵活调整检索参数和相似度阈值\n",
    "- **知识库测试**：内置查询测试和结果分析工具"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24",
   "metadata": {},
   "source": [
    "拓展资源：\n",
    "- **Cherry Studio官方文档**：https://docs.cherry-ai.com/knowledge-base/knowledge-base\n",
    "- **知识库最佳实践**：https://docs.cherry-ai.com/knowledge-base/best-practices\n",
    "- **高级检索策略**：https://docs.cherry-ai.com/knowledge-base/advanced-retrieval\n",
    "- **性能优化指南**：https://docs.cherry-ai.com/knowledge-base/performance-tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25",
   "metadata": {},
   "source": [
    "#### 2.3.1.1 创建新知识库"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26",
   "metadata": {},
   "source": [
    "1. 启动Cherry Studio，进入\"知识库\"模块\n",
    "2. 点击\"新建知识库\"，填写基本信息：\n",
    "   - 名称：企业知识库\n",
    "   - 描述：用于存储和检索企业内部文档\n",
    "   - 存储位置：本地\n",
    "   - 向量数据库：Milvus（已在环境准备中配置）\n",
    "3. 点击\"创建\"，系统将初始化知识库结构"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27",
   "metadata": {},
   "source": [
    "#### 2.3.1.2 配置知识库参数"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28",
   "metadata": {},
   "source": [
    "1. 进入知识库详情页，切换到\"设置\"标签\n",
    "2. 配置文档处理参数：\n",
    "   ```json\n",
    "   {\n",
    "     \"chunk_size\": 512,\n",
    "     \"chunk_overlap\": 50,\n",
    "     \"separator\": \"\\n\\n\",\n",
    "     \"include_metadata\": true\n",
    "   }\n",
    "   ```\n",
    "3. 配置嵌入模型：\n",
    "   - 模型名称：BAAI/bge-base-en-v1.5\n",
    "   - 批量大小：16\n",
    "   - 设备：自动\n",
    "4. 点击\"保存配置\"并应用"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29",
   "metadata": {},
   "source": [
    "### 2.3.2 文档导入与管理"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30",
   "metadata": {},
   "source": [
    "#### 2.3.2.1 导入文档\n",
    "1. 进入\"文档管理\"标签，点击\"导入文档\"\n",
    "2. 选择导入方式：\n",
    "   - 方式1：本地上传（支持多文件批量上传）\n",
    "   - 方式2：目录同步（监控指定目录自动导入）\n",
    "3. 选择测试文档（可使用课程提供的sample_docs.zip）\n",
    "4. 点击\"开始导入\"，系统将自动处理文档\n",
    "\n",
    "#### 2.3.2.2 文档处理监控\n",
    "1. 导入过程中，可在\"任务中心\"查看处理进度\n",
    "2. 处理完成后，查看文档统计信息：\n",
    "   - 总文档数：X个\n",
    "   - 总文档块数：Y个\n",
    "   - 平均分块大小：Z tokens\n",
    "3. 检查是否有处理失败的文档，点击\"重试\"处理异常文档"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31",
   "metadata": {},
   "source": [
    "### 2.3.3 检索策略配置\n",
    "\n",
    "#### 2.3.3.1 基础检索配置\n",
    "1. 进入\"检索设置\"标签，配置基础参数：\n",
    "   - 相似度阈值：0.75\n",
    "   - 返回结果数：5\n",
    "   - 重排序：启用（基于BM25）\n",
    "2. 点击\"测试检索\"，输入测试查询：\"企业核心产品有哪些？\"\n",
    "3. 查看检索结果和相关性评分，调整参数优化结果\n",
    "\n",
    "#### 2.3.3.2 高级检索策略（混合检索配置）\n",
    "1. 在\"检索设置\"中启用\"混合检索\"\n",
    "2. 配置参数：\n",
    "   - 密集向量权重：0.7\n",
    "   - 稀疏向量权重：0.3\n",
    "   - 交叉编码器重排序：启用\n",
    "3. 点击\"保存并应用\"，系统将自动重建索引\n",
    "4. 对比启用前后的检索效果差异"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32",
   "metadata": {},
   "source": [
    "### 2.3.4 知识库应用开发\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33",
   "metadata": {},
   "source": [
    "#### 2.3.4.1 创建检索应用\n",
    "1. 进入\"应用构建\"模块，点击\"新建应用\"\n",
    "2. 选择模板：\"知识库问答应用\"\n",
    "3. 配置应用参数：\n",
    "   - 名称：企业知识库问答\n",
    "   - 关联知识库：选择之前创建的\"企业知识库\"\n",
    "   - 模型：llama3:8b（本地Ollama模型）\n",
    "   - 提示词模板：使用RAG专用模板\n",
    "4. 点击\"创建应用\"，系统自动生成应用界面"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34",
   "metadata": {},
   "source": [
    "#### 2.3.4.2 应用测试与优化\n",
    "1. 进入应用详情页，点击\"预览\"\n",
    "2. 在测试界面输入问题，测试不同类型查询：\n",
    "   - 事实型：\"企业成立时间？\"\n",
    "   - 概念型：\"什么是核心竞争力？\"\n",
    "   - 分析型：\"分析产品市场优势\"\n",
    "3. 查看回答质量和引用来源，记录需要优化的案例\n",
    "4. 进入\"优化中心\"，针对低质量回答调整：\n",
    "   - 修改分块参数\n",
    "   - 优化提示词模板\n",
    "   - 调整检索策略"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35",
   "metadata": {},
   "source": [
    "### 2.3.5 知识库自动更新\n",
    "\n",
    "1. 进入知识库\"设置\"→\"自动更新\"\n",
    "2. 配置更新策略：\n",
    "   - 更新频率：每周日凌晨2点\n",
    "   - 更新范围：新增文档和修改过的文档\n",
    "   - 通知方式：邮件通知\n",
    "3. 点击\"启用自动更新\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36",
   "metadata": {},
   "source": [
    "### 2.3.6 常见问题与解决方案\n",
    "\n",
    "#### 文档导入失败\n",
    "**问题**：PDF文档导入后内容为空  \n",
    "**解决方案**：\n",
    "1. 检查PDF是否加密或扫描件（需OCR处理）\n",
    "2. 进入\"设置\"→\"文档处理\"，启用\"高级PDF解析\"\n",
    "3. 重新导入文档\n",
    "\n",
    "#### 检索结果相关性低\n",
    "**问题**：查询结果与问题相关性差  \n",
    "**解决方案**：\n",
    "1. 降低相似度阈值（如从0.8调整至0.7）\n",
    "2. 增加chunk_overlap至100\n",
    "3. 尝试不同的嵌入模型（如切换至bge-large模型）\n",
    "\n",
    "#### 知识库体积过大\n",
    "**问题**：知识库文档过多导致检索缓慢  \n",
    "**解决方案**：\n",
    "1. 启用\"分层检索\"（设置知识库层级结构）\n",
    "2. 配置\"自动归档\"策略，将旧文档移至归档库\n",
    "3. 优化索引参数，使用IVF_FLAT索引类型"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37",
   "metadata": {},
   "source": [
    "## 2.4 RAG提示词工程\n",
    "\n",
    "### 2.4.1 检索增强提示结构\n",
    "```markdown\n",
    "# 系统角色\n",
    "你是企业知识库问答专家，使用提供的检索结果回答问题。\n",
    "\n",
    "## 检索结果使用规则\n",
    "- 仅使用检索到的内容回答问题\n",
    "- 明确引用来源文档和页码\n",
    "- 对冲突信息标注\"信息冲突：来源A认为...来源B认为...\"\n",
    "\n",
    "## 输出格式\n",
    "**回答**：[基于检索内容的回答]\n",
    "**来源**：[引用文档列表]\n",
    "**检索建议**：[如果信息不足，建议补充的检索关键词]\n",
    "```\n",
    "\n",
    "### 2.4.2 提示词优化技巧\n",
    "1. **指定回答风格**：\n",
    "```markdown\n",
    "# 回答风格\n",
    "- 使用简洁的要点形式回答\n",
    "- 每点不超过20个字\n",
    "- 重点内容加粗显示\n",
    "```\n",
    "\n",
    "2. **多轮检索提示**：\n",
    "```markdown\n",
    "# 多轮检索优化\n",
    "如果第一次检索结果不足以回答问题：\n",
    "1. 分析缺失的信息\n",
    "2. 生成补充检索关键词\n",
    "3. 进行二次检索\n",
    "4. 综合两次结果回答\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38",
   "metadata": {},
   "source": [
    "## 2.5 课程作业：企业知识库系统开发\n",
    "\n",
    "### 2.5.1 作业目标\n",
    "使用Cherry Studio构建一个完整的企业知识库系统，实现文档管理、智能检索和问答功能。\n",
    "\n",
    "### 2.5.2 具体要求\n",
    "1. **知识库构建**：\n",
    "   - 导入至少10篇不同类型的企业文档\n",
    "   - 配置混合检索策略\n",
    "   - 优化分块和嵌入参数\n",
    "\n",
    "2. **应用开发**：\n",
    "   - 创建知识库问答应用\n",
    "   - 实现自定义提示词模板\n",
    "   - 添加结果可视化功能\n",
    "\n",
    "3. **性能优化**：\n",
    "   - 对比不同检索策略的效果\n",
    "   - 分析并优化低相关性查询案例\n",
    "   - 生成性能测试报告\n",
    "\n",
    "### 提交内容\n",
    "- 知识库配置截图\n",
    "- 应用界面截图\n",
    "- 5组测试查询的问答记录\n",
    "- 优化前后的性能对比报告\n",
    "- 技术总结（500字以内）"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LLM-Agent-Lab",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
